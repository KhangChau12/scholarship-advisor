"""
Coordinator Agent - Agent Ä‘iá»u phá»‘i trung tÃ¢m
Nhiá»‡m vá»¥: Nháº­n yÃªu cáº§u, phÃ¢n tÃ­ch thÃ´ng tin, Ä‘iá»u phá»‘i cÃ¡c agent khÃ¡c
"""
import os
import asyncio
import json
from typing import Dict, List, Any, Optional
from loguru import logger

from ..utils.llm_client import llm_manager
from ..config.prompts import COORDINATOR_PROMPT, VIETNAMESE_STUDENT_CONTEXT
from ..tools.file_processor import file_processor

class CoordinatorAgent:
    """Agent Ä‘iá»u phá»‘i trung tÃ¢m"""
    
    def __init__(self):
        self.name = "CoordinatorAgent"
        self.llm = llm_manager
        
    async def process_initial_request(
        self,
        user_message: str,
        uploaded_files: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        Xá»­ lÃ½ yÃªu cáº§u ban Ä‘áº§u tá»« há»c sinh
        
        Args:
            user_message: Tin nháº¯n tá»« há»c sinh
            uploaded_files: Danh sÃ¡ch file upload (náº¿u cÃ³)
            
        Returns:
            ThÃ´ng tin Ä‘Ã£ phÃ¢n tÃ­ch vÃ  káº¿ hoáº¡ch xá»­ lÃ½
        """
        logger.info(f"Coordinator processing request: {user_message[:100]}...")
        
        try:
            # PhÃ¢n tÃ­ch yÃªu cáº§u ban Ä‘áº§u
            analysis_result = await self._analyze_user_request(user_message)
            
            # Xá»­ lÃ½ file upload náº¿u cÃ³
            file_analysis = {}
            if uploaded_files:
                file_analysis = await self._process_uploaded_files(uploaded_files)
            
            # Táº¡o káº¿ hoáº¡ch xá»­ lÃ½
            processing_plan = self._create_processing_plan(analysis_result, file_analysis)
            
            return {
                "success": True,
                "user_request": user_message,
                "analysis": analysis_result,
                "file_analysis": file_analysis,
                "processing_plan": processing_plan,
                "next_agents": self._determine_next_agents(analysis_result)
            }
            
        except Exception as e:
            logger.error(f"Error in coordinator: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "user_request": user_message
            }
    
    async def _analyze_user_request(self, user_message: str) -> Dict[str, Any]:
        """PhÃ¢n tÃ­ch yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng"""
        
        system_prompt = f"""
        {COORDINATOR_PROMPT}
        
        {VIETNAMESE_STUDENT_CONTEXT}
        
        HÃ£y phÃ¢n tÃ­ch yÃªu cáº§u cá»§a há»c sinh vÃ  trÃ­ch xuáº¥t thÃ´ng tin quan trá»ng.
        """
        
        messages = [
            {
                "role": "user", 
                "content": f"YÃªu cáº§u cá»§a há»c sinh: {user_message}"
            }
        ]
        
        response = await self.llm.get_structured_response(
            messages=messages,
            system_prompt=system_prompt,
            schema={
                "target_country": "string",
                "field_of_study": "string", 
                "degree_level": "string",
                "budget_range": "string",
                "profile_summary": "string",
                "completeness_score": "number 0-100",
                "missing_info": ["list of missing information"],
                "clarification_questions": ["list of questions to ask user"]
            }
        )
        
        return response
    
    async def _process_uploaded_files(self, file_paths: List[str]) -> Dict[str, Any]:
        """Xá»­ lÃ½ cÃ¡c file Ä‘Æ°á»£c upload"""
        
        file_results = []
        
        for file_path in file_paths:
            try:
                # Validate file
                file_size = os.path.getsize(file_path)
                validation = file_processor.validate_file(file_path, file_size)
                
                if not validation["valid"]:
                    file_results.append({
                        "file": file_path,
                        "success": False,
                        "errors": validation["errors"]
                    })
                    continue
                
                # Process file
                processing_result = await file_processor.process_student_profile(file_path)
                
                if processing_result["success"]:
                    # Calculate profile score
                    profile_score = file_processor.calculate_profile_score(
                        processing_result["profile"]
                    )
                    
                    file_results.append({
                        "file": file_path,
                        "success": True,
                        "profile": processing_result["profile"],
                        "score": profile_score,
                        "content_preview": processing_result["raw_content"]
                    })
                else:
                    file_results.append({
                        "file": file_path,
                        "success": False,
                        "error": processing_result["error"]
                    })
                    
            except Exception as e:
                logger.error(f"Error processing file {file_path}: {str(e)}")
                file_results.append({
                    "file": file_path,
                    "success": False,
                    "error": str(e)
                })
        
        return {
            "total_files": len(file_paths),
            "successful_files": len([r for r in file_results if r["success"]]),
            "results": file_results
        }
    
    def _create_processing_plan(
        self,
        analysis_result: Dict[str, Any],
        file_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Táº¡o káº¿ hoáº¡ch xá»­ lÃ½ cho cÃ¡c agent tiáº¿p theo"""
        
        plan = {
            "workflow_steps": [],
            "estimated_time": 0,
            "complexity": "medium"
        }
        
        # XÃ¡c Ä‘á»‹nh Ä‘á»™ phá»©c táº¡p
        completeness = analysis_result.get("completeness_score", 50)
        has_files = file_analysis.get("successful_files", 0) > 0
        
        if completeness >= 80 and has_files:
            plan["complexity"] = "low"
            plan["estimated_time"] = 180  # 3 minutes
        elif completeness >= 60:
            plan["complexity"] = "medium" 
            plan["estimated_time"] = 300  # 5 minutes
        else:
            plan["complexity"] = "high"
            plan["estimated_time"] = 600  # 10 minutes
        
        # XÃ¡c Ä‘á»‹nh cÃ¡c bÆ°á»›c workflow
        if completeness < 70:
            plan["workflow_steps"].append({
                "step": "clarification",
                "description": "Cáº§n lÃ m rÃµ thÃ´ng tin vá»›i há»c sinh",
                "questions": analysis_result.get("clarification_questions", [])
            })
        
        plan["workflow_steps"].extend([
            {
                "step": "scholarship_search",
                "description": "TÃ¬m kiáº¿m há»c bá»•ng phÃ¹ há»£p",
                "agent": "ScholarshipFinderAgent"
            },
            {
                "step": "profile_analysis", 
                "description": "PhÃ¢n tÃ­ch há»“ sÆ¡ há»c sinh",
                "agent": "ProfileAnalyzerAgent"
            },
            {
                "step": "financial_calculation",
                "description": "TÃ­nh toÃ¡n chi phÃ­ vÃ  tÃ i chÃ­nh",
                "agent": "FinancialCalculatorAgent"
            },
            {
                "step": "comprehensive_advice",
                "description": "TÆ° váº¥n tá»•ng há»£p vÃ  káº¿ hoáº¡ch hÃ nh Ä‘á»™ng",
                "agent": "AdvisorAgent"
            }
        ])
        
        return plan
    
    def _determine_next_agents(self, analysis_result: Dict[str, Any]) -> List[str]:
        """XÃ¡c Ä‘á»‹nh thá»© tá»± cÃ¡c agent tiáº¿p theo"""
        
        completeness = analysis_result.get("completeness_score", 50)
        
        if completeness < 70:
            # Cáº§n clarification trÆ°á»›c
            return ["clarification_needed"]
        
        # Workflow bÃ¬nh thÆ°á»ng
        return [
            "ScholarshipFinderAgent",
            "ProfileAnalyzerAgent", 
            "FinancialCalculatorAgent",
            "AdvisorAgent"
        ]
    
    async def clarify_information(
        self,
        original_request: str,
        user_response: str,
        previous_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        LÃ m rÃµ thÃ´ng tin dá»±a trÃªn pháº£n há»“i cá»§a ngÆ°á»i dÃ¹ng
        
        Args:
            original_request: YÃªu cáº§u ban Ä‘áº§u
            user_response: Pháº£n há»“i cá»§a ngÆ°á»i dÃ¹ng
            previous_analysis: PhÃ¢n tÃ­ch trÆ°á»›c Ä‘Ã³
            
        Returns:
            ThÃ´ng tin Ä‘Ã£ Ä‘Æ°á»£c lÃ m rÃµ
        """
        
        system_prompt = f"""
        {COORDINATOR_PROMPT}
        
        Báº¡n Ä‘Ã£ phÃ¢n tÃ­ch yÃªu cáº§u ban Ä‘áº§u vÃ  nháº­n Ä‘Æ°á»£c thÃªm thÃ´ng tin tá»« há»c sinh.
        HÃ£y cáº­p nháº­t vÃ  hoÃ n thiá»‡n thÃ´ng tin.
        """
        
        messages = [
            {
                "role": "user",
                "content": f"""
                YÃªu cáº§u ban Ä‘áº§u: {original_request}
                
                PhÃ¢n tÃ­ch trÆ°á»›c Ä‘Ã³: {json.dumps(previous_analysis, ensure_ascii=False)}
                
                ThÃ´ng tin bá»• sung tá»« há»c sinh: {user_response}
                
                HÃ£y cáº­p nháº­t vÃ  hoÃ n thiá»‡n thÃ´ng tin.
                """
            }
        ]
        
        response = await self.llm.get_structured_response(
            messages=messages,
            system_prompt=system_prompt,
            schema={
                "target_country": "string",
                "field_of_study": "string",
                "degree_level": "string", 
                "budget_range": "string",
                "profile_summary": "string",
                "completeness_score": "number 0-100",
                "updated_info": "string describing what was updated",
                "ready_for_processing": "boolean"
            }
        )
        
        return response
    
    def get_progress_message(self, step: str) -> str:
        """Táº¡o thÃ´ng bÃ¡o tiáº¿n trÃ¬nh cho UI"""
        
        progress_messages = {
            "analyzing": "ğŸ§  Äang phÃ¢n tÃ­ch yÃªu cáº§u cá»§a báº¡n...",
            "processing_files": "ğŸ“„ Äang xá»­ lÃ½ há»“ sÆ¡ cá»§a báº¡n...",
            "creating_plan": "ğŸ“‹ Äang táº¡o káº¿ hoáº¡ch tÆ° váº¥n...",
            "searching_scholarships": "ğŸ” Äang tÃ¬m kiáº¿m há»c bá»•ng phÃ¹ há»£p...",
            "analyzing_profile": "ğŸ“Š Äang phÃ¢n tÃ­ch Ä‘iá»ƒm máº¡nh cá»§a báº¡n...",
            "calculating_costs": "ğŸ’° Äang tÃ­nh toÃ¡n chi phÃ­ du há»c...",
            "generating_advice": "ğŸ¯ Äang táº¡o tÆ° váº¥n cÃ¡ nhÃ¢n hÃ³a...",
            "finalizing": "âœ¨ Äang hoÃ n thiá»‡n káº¿t quáº£..."
        }
        
        return progress_messages.get(step, "âš™ï¸ Äang xá»­ lÃ½...")

# Global coordinator instance
coordinator_agent = CoordinatorAgent()